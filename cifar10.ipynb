{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M0whDfgBSVk",
        "colab_type": "text"
      },
      "source": [
        "# NNとCNNの比較"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVe-35hBpAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import keras\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.datasets import cifar10,mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNk7HiCaBwSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#precision\n",
        "def P(y_true, y_pred):\n",
        "    true_positives = K.sum(K.cast(K.greater(K.clip(y_true * y_pred, 0, 1), 0.20), 'float32'))\n",
        "    pred_positives = K.sum(K.cast(K.greater(K.clip(y_pred, 0, 1), 0.20), 'float32'))\n",
        "\n",
        "    precision = true_positives / (pred_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "#recall\n",
        "def R(y_true, y_pred):\n",
        "    true_positives = K.sum(K.cast(K.greater(K.clip(y_true * y_pred, 0, 1), 0.20), 'float32'))\n",
        "    poss_positives = K.sum(K.cast(K.greater(K.clip(y_true, 0, 1), 0.20), 'float32'))\n",
        "\n",
        "    recall = true_positives / (poss_positives + K.epsilon())\n",
        "    return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8fztakByvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model():\n",
        "  nn_model = Sequential()\n",
        "  nn_model.add(Dense(512, input_shape=x_train_nn.shape[1:]))\n",
        "  nn_model.add(Activation('relu'))\n",
        "  nn_model.add(Dense(10))\n",
        "  nn_model.add(Activation('softmax'))\n",
        "  nn_model.summary()\n",
        "  nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',P,R])\n",
        "  return nn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQ0jParCiWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model():\n",
        "  cnn_model = Sequential()\n",
        "  cnn_model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32,32,3)))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(Conv2D(32, (3, 3)))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "  cnn_model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(Conv2D(64, (3, 3)))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "  cnn_model.add(Flatten())\n",
        "  cnn_model.add(Dense(512))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(Dropout(0.5))\n",
        "  cnn_model.add(Dense(10))\n",
        "  cnn_model.add(Activation('softmax'))\n",
        "  cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',P,R])\n",
        "  return cnn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYlZcmV1BLCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "01bc3a82-c2d6-4441-d397-5dbed83187e1"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "#x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "#x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
        "x_train_nn = x_train.reshape(x_train.shape[0], 3072)#784 3072\n",
        "x_test_nn = x_test.reshape(x_test.shape[0], 3072)\n",
        "#print(x_train_nn.shape,y_train.shape,x_test_nn.shape,y_test.shape)\n",
        "x_train_nn = x_train_nn.astype('float32')\n",
        "x_test_nn = x_test_nn.astype('float32')\n",
        "x_train_nn /= 255\n",
        "x_test_nn /= 255\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "model = nn_model()\n",
        "model.fit(x_train_nn, y_train, batch_size=128, epochs=5, validation_split=0.1)\n",
        "score = model.evaluate(x_test_nn, y_test)\n",
        "pred = model.predict(x_test_nn)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "Y = np.argmax(y_test,axis=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(confusion_matrix(pred,Y))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_71 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,578,506\n",
            "Trainable params: 1,578,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "45000/45000 [==============================] - 17s 375us/step - loss: 1.9363 - acc: 0.3188 - P: 0.3094 - R: 0.3910 - val_loss: 1.8561 - val_acc: 0.3436 - val_P: 0.3277 - val_R: 0.4444\n",
            "Epoch 2/5\n",
            "45000/45000 [==============================] - 16s 354us/step - loss: 1.7354 - acc: 0.3845 - P: 0.3497 - R: 0.4990 - val_loss: 1.6937 - val_acc: 0.4050 - val_P: 0.3606 - val_R: 0.5214\n",
            "Epoch 3/5\n",
            "45000/45000 [==============================] - 16s 364us/step - loss: 1.6636 - acc: 0.4097 - P: 0.3614 - R: 0.5360 - val_loss: 1.6389 - val_acc: 0.4168 - val_P: 0.3720 - val_R: 0.5370\n",
            "Epoch 4/5\n",
            "45000/45000 [==============================] - 16s 356us/step - loss: 1.5894 - acc: 0.4383 - P: 0.3791 - R: 0.5735 - val_loss: 1.6246 - val_acc: 0.4216 - val_P: 0.3708 - val_R: 0.5602\n",
            "Epoch 5/5\n",
            "45000/45000 [==============================] - 16s 361us/step - loss: 1.5582 - acc: 0.4494 - P: 0.3860 - R: 0.5857 - val_loss: 1.5686 - val_acc: 0.4544 - val_P: 0.3770 - val_R: 0.5878\n",
            "10000/10000 [==============================] - 2s 158us/step\n",
            "Test loss: 1.5579567733764648\n",
            "Test accuracy: 0.4453\n",
            "[[580  73 136  60  84  53  17  82 159  77]\n",
            " [ 35 565  42  31  14  23  15  20  60 201]\n",
            " [ 48  19 322 129 160 136 111  84  16  17]\n",
            " [ 11   7  44 209  26 127  73  40  13  20]\n",
            " [ 65  21 205 105 454 105 207 121  25  31]\n",
            " [ 11  23  68 229  50 323  76  80  18  26]\n",
            " [ 13  16  81  75  89  74 416  16   8  14]\n",
            " [ 26  37  55  57  79  81  50 493  16  56]\n",
            " [176 103  36  48  32  57  20  17 628  95]\n",
            " [ 35 136  11  57  12  21  15  47  57 463]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}