{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M0whDfgBSVk",
        "colab_type": "text"
      },
      "source": [
        "# NNとCNNの比較"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVe-35hBpAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import keras\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.datasets import cifar10,mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNk7HiCaBwSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#precision\n",
        "def P(y_true, y_pred):\n",
        "    true_positives = K.sum(K.cast(K.greater(K.clip(y_true * y_pred, 0, 1), 0.20), 'float32'))\n",
        "    pred_positives = K.sum(K.cast(K.greater(K.clip(y_pred, 0, 1), 0.20), 'float32'))\n",
        "\n",
        "    precision = true_positives / (pred_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "#recall\n",
        "def R(y_true, y_pred):\n",
        "    true_positives = K.sum(K.cast(K.greater(K.clip(y_true * y_pred, 0, 1), 0.20), 'float32'))\n",
        "    poss_positives = K.sum(K.cast(K.greater(K.clip(y_true, 0, 1), 0.20), 'float32'))\n",
        "\n",
        "    recall = true_positives / (poss_positives + K.epsilon())\n",
        "    return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8fztakByvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model():\n",
        "  nn_model = Sequential()\n",
        "  nn_model.add(Dense(512, input_shape=x_train_nn.shape[1:]))\n",
        "  nn_model.add(Activation('relu'))\n",
        "  nn_model.add(Dense(10))\n",
        "  nn_model.add(Activation('softmax'))\n",
        "  nn_model.summary()\n",
        "  nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',P,R])\n",
        "  return nn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQ0jParCiWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model():\n",
        "  cnn_model = Sequential()\n",
        "  cnn_model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32,32,3)))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(Conv2D(32, (3, 3)))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "  cnn_model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(Conv2D(64, (3, 3)))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "  cnn_model.add(Flatten())\n",
        "  cnn_model.add(Dense(512))\n",
        "  cnn_model.add(Activation('relu'))\n",
        "  cnn_model.add(Dropout(0.5))\n",
        "  cnn_model.add(Dense(10))\n",
        "  cnn_model.add(Activation('softmax'))\n",
        "  cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',P,R])\n",
        "  return cnn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYlZcmV1BLCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "479626e5-ebb9-4e2b-f886-1a9f17f9b4ab"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
        "x_train_nn = x_train.reshape(x_train.shape[0], 784)\n",
        "x_test_nn = x_test.reshape(x_test.shape[0], 784)\n",
        "print(x_train_nn.shape,y_train.shape,x_test_nn.shape,y_test.shape)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "model = nn_model()\n",
        "model.fit(x_train_nn, y_train, batch_size=128, epochs=5, validation_split=0.1)\n",
        "score = model.evaluate(x_test_nn, y_test)\n",
        "pred = model.predict(x_test_nn)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "Y = np.argmax(y_test,axis=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(confusion_matrix(pred,Y))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,)\n",
            "(60000, 784) (60000,) (10000, 784) (10000,)\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_63 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/5\n",
            "54000/54000 [==============================] - 7s 129us/step - loss: 12.2218 - acc: 0.2408 - P: 0.2406 - R: 0.2409 - val_loss: 11.9690 - val_acc: 0.2572 - val_P: 0.2569 - val_R: 0.2572\n",
            "Epoch 2/5\n",
            "54000/54000 [==============================] - 6s 103us/step - loss: 11.8878 - acc: 0.2621 - P: 0.2619 - R: 0.2622 - val_loss: 11.8791 - val_acc: 0.2630 - val_P: 0.2627 - val_R: 0.2630\n",
            "Epoch 3/5\n",
            "54000/54000 [==============================] - 6s 106us/step - loss: 11.8453 - acc: 0.2648 - P: 0.2647 - R: 0.2649 - val_loss: 11.7321 - val_acc: 0.2715 - val_P: 0.2715 - val_R: 0.2717\n",
            "Epoch 4/5\n",
            "54000/54000 [==============================] - 5s 100us/step - loss: 10.7413 - acc: 0.3332 - P: 0.3331 - R: 0.3333 - val_loss: 10.7743 - val_acc: 0.3313 - val_P: 0.3312 - val_R: 0.3313\n",
            "Epoch 5/5\n",
            "54000/54000 [==============================] - 6s 106us/step - loss: 10.4280 - acc: 0.3526 - P: 0.3526 - R: 0.3527 - val_loss: 10.1816 - val_acc: 0.3682 - val_P: 0.3681 - val_R: 0.3683\n",
            "10000/10000 [==============================] - 1s 73us/step\n",
            "Test loss: 10.274520765686034\n",
            "Test accuracy: 0.3624\n",
            "[[   0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0]\n",
            " [  96 1080  716  941    0   46   10  137  337   24]\n",
            " [   0    0    0    0    0    0    0    0    0    0]\n",
            " [ 652   29   18   44    6  798   22    5  420   11]\n",
            " [ 193   22  194    6   26   22  913    1   44    2]\n",
            " [   0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0]\n",
            " [  39    4  104   19  950   26   13  885  173  972]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}